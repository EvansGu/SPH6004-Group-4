{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>aniongap</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bun</th>\n",
       "      <th>calcium</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>glucose</th>\n",
       "      <th>sodium</th>\n",
       "      <th>potassium</th>\n",
       "      <th>...</th>\n",
       "      <th>admission_type_URGENT</th>\n",
       "      <th>first_careunit_Cardiac Vascular Intensive Care Unit (CVICU)</th>\n",
       "      <th>first_careunit_Coronary Care Unit (CCU)</th>\n",
       "      <th>first_careunit_Medical Intensive Care Unit (MICU)</th>\n",
       "      <th>first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)</th>\n",
       "      <th>first_careunit_Neuro Intermediate</th>\n",
       "      <th>first_careunit_Neuro Stepdown</th>\n",
       "      <th>first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)</th>\n",
       "      <th>first_careunit_Surgical Intensive Care Unit (SICU)</th>\n",
       "      <th>first_careunit_Trauma SICU (TSICU)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001305.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>154.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001305.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>149.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001305.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>131.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001361.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>161.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001361.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>124.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93599</th>\n",
       "      <td>29999498.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93600</th>\n",
       "      <td>29999498.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93601</th>\n",
       "      <td>29999625.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>109.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93602</th>\n",
       "      <td>29999625.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>122.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93603</th>\n",
       "      <td>29999625.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>122.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93604 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  aniongap  bicarbonate   bun  calcium  chloride  creatinine  \\\n",
       "0      20001305.0      15.0         23.0  47.0     11.4     108.0         0.8   \n",
       "1      20001305.0      13.0         25.0  48.0     10.8     107.0         0.9   \n",
       "2      20001305.0      13.0         24.0  50.0     10.8     108.0         0.9   \n",
       "3      20001361.0      14.0         22.0  28.0      6.3     107.0         2.5   \n",
       "4      20001361.0      15.0         20.0  32.0      6.5     108.0         2.5   \n",
       "...           ...       ...          ...   ...      ...       ...         ...   \n",
       "93599  29999498.0      20.0         22.0  13.0     11.2     100.0         1.2   \n",
       "93600  29999498.0      15.0         21.0  13.0     10.1     103.0         1.2   \n",
       "93601  29999625.0      17.0         21.0  14.0      8.5     104.0         1.2   \n",
       "93602  29999625.0      15.0         24.0  21.0      8.6     110.0         1.6   \n",
       "93603  29999625.0      15.0         24.0  21.0      8.6     110.0         1.6   \n",
       "\n",
       "       glucose  sodium  potassium  ...  admission_type_URGENT  \\\n",
       "0        154.0   142.0        4.3  ...                      0   \n",
       "1        149.0   140.0        4.7  ...                      0   \n",
       "2        131.0   141.0        4.1  ...                      0   \n",
       "3        161.0   137.0        5.8  ...                      0   \n",
       "4        124.0   137.0        5.7  ...                      0   \n",
       "...        ...     ...        ...  ...                    ...   \n",
       "93599     76.0   137.0        4.6  ...                      0   \n",
       "93600    102.0   135.0        4.2  ...                      0   \n",
       "93601    109.0   142.0        4.6  ...                      0   \n",
       "93602    122.0   149.0        4.1  ...                      0   \n",
       "93603    122.0   148.0        4.1  ...                      0   \n",
       "\n",
       "       first_careunit_Cardiac Vascular Intensive Care Unit (CVICU)  \\\n",
       "0                                                      0             \n",
       "1                                                      0             \n",
       "2                                                      0             \n",
       "3                                                      0             \n",
       "4                                                      0             \n",
       "...                                                  ...             \n",
       "93599                                                  0             \n",
       "93600                                                  0             \n",
       "93601                                                  0             \n",
       "93602                                                  0             \n",
       "93603                                                  0             \n",
       "\n",
       "       first_careunit_Coronary Care Unit (CCU)  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "...                                        ...   \n",
       "93599                                        0   \n",
       "93600                                        0   \n",
       "93601                                        0   \n",
       "93602                                        0   \n",
       "93603                                        0   \n",
       "\n",
       "       first_careunit_Medical Intensive Care Unit (MICU)  \\\n",
       "0                                                      0   \n",
       "1                                                      0   \n",
       "2                                                      0   \n",
       "3                                                      0   \n",
       "4                                                      0   \n",
       "...                                                  ...   \n",
       "93599                                                  0   \n",
       "93600                                                  0   \n",
       "93601                                                  0   \n",
       "93602                                                  0   \n",
       "93603                                                  0   \n",
       "\n",
       "       first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)  \\\n",
       "0                                                      1                 \n",
       "1                                                      1                 \n",
       "2                                                      1                 \n",
       "3                                                      1                 \n",
       "4                                                      1                 \n",
       "...                                                  ...                 \n",
       "93599                                                  1                 \n",
       "93600                                                  1                 \n",
       "93601                                                  0                 \n",
       "93602                                                  0                 \n",
       "93603                                                  0                 \n",
       "\n",
       "       first_careunit_Neuro Intermediate  first_careunit_Neuro Stepdown  \\\n",
       "0                                      0                              0   \n",
       "1                                      0                              0   \n",
       "2                                      0                              0   \n",
       "3                                      0                              0   \n",
       "4                                      0                              0   \n",
       "...                                  ...                            ...   \n",
       "93599                                  0                              0   \n",
       "93600                                  0                              0   \n",
       "93601                                  0                              0   \n",
       "93602                                  0                              0   \n",
       "93603                                  0                              0   \n",
       "\n",
       "       first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)  \\\n",
       "0                                                      0                \n",
       "1                                                      0                \n",
       "2                                                      0                \n",
       "3                                                      0                \n",
       "4                                                      0                \n",
       "...                                                  ...                \n",
       "93599                                                  0                \n",
       "93600                                                  0                \n",
       "93601                                                  1                \n",
       "93602                                                  1                \n",
       "93603                                                  1                \n",
       "\n",
       "       first_careunit_Surgical Intensive Care Unit (SICU)  \\\n",
       "0                                                      0    \n",
       "1                                                      0    \n",
       "2                                                      0    \n",
       "3                                                      0    \n",
       "4                                                      0    \n",
       "...                                                  ...    \n",
       "93599                                                  0    \n",
       "93600                                                  0    \n",
       "93601                                                  0    \n",
       "93602                                                  0    \n",
       "93603                                                  0    \n",
       "\n",
       "       first_careunit_Trauma SICU (TSICU)  \n",
       "0                                       0  \n",
       "1                                       0  \n",
       "2                                       0  \n",
       "3                                       0  \n",
       "4                                       0  \n",
       "...                                   ...  \n",
       "93599                                   0  \n",
       "93600                                   0  \n",
       "93601                                   0  \n",
       "93602                                   0  \n",
       "93603                                   0  \n",
       "\n",
       "[93604 rows x 99 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"df_imputed.csv\")\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "deceased_df = data[data['icu_death'] == 1]\n",
    "survived_df = data[data['icu_death'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aniongap                                                          0.113425\n",
      "bicarbonate                                                       0.072689\n",
      "bun                                                               0.034244\n",
      "calcium                                                           0.035887\n",
      "chloride                                                          0.003144\n",
      "                                                                    ...   \n",
      "first_careunit_Neuro Intermediate                                 0.006795\n",
      "first_careunit_Neuro Stepdown                                     0.007410\n",
      "first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)    0.022016\n",
      "first_careunit_Surgical Intensive Care Unit (SICU)                0.062911\n",
      "first_careunit_Trauma SICU (TSICU)                                0.009650\n",
      "Name: los_icu, Length: 97, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "deceased_df.drop('id', axis=1, inplace=True)\n",
    "correlation_matrix = deceased_df.corr()\n",
    "abs_target_correlation = correlation_matrix['los_icu'].abs()\n",
    "\n",
    "print(abs_target_correlation.drop('los_icu', axis=0))\n",
    "N = 30 \n",
    "top_features = abs_target_correlation.drop('los_icu', axis=0).nlargest(N).index.tolist()\n",
    "\n",
    "X = deceased_df[top_features]\n",
    "y=deceased_df['los_icu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Partition the data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tfa.layers.MultiHeadAttention(head_size=embed_dim // num_heads, num_heads=num_heads)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim)  # Make sure the output of FFN matches embed_dim\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att([inputs, inputs, inputs])\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embed_dim, num_heads, ff_dim):\n",
    "    input_shape = (sequence_length, embed_dim)  # input shape\n",
    "    model = Sequential([\n",
    "        TransformerBlock(embed_dim, num_heads, ff_dim),\n",
    "        Dense(1)  # Adjust the output layer to the task\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# Use KerasClassifier to wrap the model\n",
    "model = KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "# 定义你的参数网格\n",
    "param_grid = {\n",
    "    'embed_dim': [30,60],  # Input feature dimensions\n",
    "    'num_heads': [2,3,4],    # Head count\n",
    "    'ff_dim': [64,128,256],    # Internal dimensions of FFN\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform a grid search\n",
    "grid_result = grid_search.fit(X_train, y_train,batch_size=32, epochs=10, validation_split=0.2)  # 使用填充后的数据\n",
    "\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 3  \n",
    "\n",
    "if X_train.shape[1] < sequence_length:\n",
    "    # If the number of features is less than the sequence length, you may need to pad the data\n",
    "    padding = np.zeros((X_train.shape[0], sequence_length - X_train.shape[1], X_train.shape[2]))\n",
    "    X_train_padded = np.concatenate([X_train, padding], axis=1)\n",
    "else:\n",
    "    # If the number of features is more than or equal to the sequence length, the data can be reshaped or split\n",
    "    X_train_reshaped = X_train.reshape(-1, sequence_length, X_train.shape[1] // sequence_length)\n",
    "    \n",
    "if X_test.shape[1] < sequence_length:\n",
    "    # If the number of features is less than the sequence length, you may need to pad the data\n",
    "    padding = np.zeros((X_test.shape[0], sequence_length - X_test.shape[1], X_test.shape[2]))\n",
    "    X_test_padded = np.concatenate([X_test, padding], axis=1)\n",
    "else:\n",
    "    # If the number of features is more than or equal to the sequence length, the data can be reshaped or split\n",
    "    X_test_reshaped = X_test.reshape(-1, sequence_length, X_test.shape[1] // sequence_length)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:121: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 8s 11ms/step - loss: 59.4909 - val_loss: 61.2528\n",
      "Epoch 2/100\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 55.7093 - val_loss: 58.4589\n",
      "Epoch 3/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 51.9369 - val_loss: 54.2581\n",
      "Epoch 4/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 48.7809 - val_loss: 50.0679\n",
      "Epoch 5/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 45.4648 - val_loss: 46.5986\n",
      "Epoch 6/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 42.2449 - val_loss: 44.6517\n",
      "Epoch 7/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 39.3676 - val_loss: 41.2941\n",
      "Epoch 8/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 36.9617 - val_loss: 38.9429\n",
      "Epoch 9/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 34.3682 - val_loss: 36.4820\n",
      "Epoch 10/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 31.7889 - val_loss: 35.1937\n",
      "Epoch 11/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 29.3497 - val_loss: 33.1342\n",
      "Epoch 12/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 27.5635 - val_loss: 34.5035\n",
      "Epoch 13/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 26.1251 - val_loss: 29.6593\n",
      "Epoch 14/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 24.8247 - val_loss: 28.0429\n",
      "Epoch 15/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 23.2500 - val_loss: 27.5882\n",
      "Epoch 16/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 21.6548 - val_loss: 25.9054\n",
      "Epoch 17/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 20.1731 - val_loss: 26.8735\n",
      "Epoch 18/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 19.3826 - val_loss: 25.7887\n",
      "Epoch 19/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 19.1524 - val_loss: 23.5747\n",
      "Epoch 20/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 18.7642 - val_loss: 23.4851\n",
      "Epoch 21/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 16.7707 - val_loss: 24.2532\n",
      "Epoch 22/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 16.5387 - val_loss: 25.8803\n",
      "Epoch 23/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 16.2650 - val_loss: 24.4518\n",
      "Epoch 24/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 15.5767 - val_loss: 22.8100\n",
      "Epoch 25/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 14.6176 - val_loss: 22.5713\n",
      "Epoch 26/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 16.1320 - val_loss: 22.9495\n",
      "Epoch 27/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 14.5589 - val_loss: 21.6408\n",
      "Epoch 28/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 13.5259 - val_loss: 21.1620\n",
      "Epoch 29/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 13.6892 - val_loss: 20.7916\n",
      "Epoch 30/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 13.8380 - val_loss: 20.7507\n",
      "Epoch 31/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 13.7172 - val_loss: 21.0986\n",
      "Epoch 32/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 13.0128 - val_loss: 21.6057\n",
      "Epoch 33/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 12.2546 - val_loss: 20.2089\n",
      "Epoch 34/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 12.5211 - val_loss: 20.2505\n",
      "Epoch 35/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 12.2356 - val_loss: 21.3781\n",
      "Epoch 36/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 12.4469 - val_loss: 19.5786\n",
      "Epoch 37/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 12.1389 - val_loss: 19.8960\n",
      "Epoch 38/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 11.7800 - val_loss: 20.3664\n",
      "Epoch 39/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 11.3240 - val_loss: 19.2504\n",
      "Epoch 40/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 10.9658 - val_loss: 18.7426\n",
      "Epoch 41/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 11.2754 - val_loss: 17.9254\n",
      "Epoch 42/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 10.4792 - val_loss: 18.4761\n",
      "Epoch 43/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 10.5206 - val_loss: 18.0232\n",
      "Epoch 44/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 10.8025 - val_loss: 18.0276\n",
      "Epoch 45/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 10.4767 - val_loss: 19.0197\n",
      "Epoch 46/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 10.5266 - val_loss: 18.6840\n",
      "Epoch 47/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 9.7450 - val_loss: 17.5035\n",
      "Epoch 48/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 10.0343 - val_loss: 18.0995\n",
      "Epoch 49/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 9.9805 - val_loss: 18.0917\n",
      "Epoch 50/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 9.4336 - val_loss: 17.6415\n",
      "Epoch 51/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 9.2671 - val_loss: 16.5098\n",
      "Epoch 52/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 9.4161 - val_loss: 17.8167\n",
      "Epoch 53/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 8.8422 - val_loss: 16.8739\n",
      "Epoch 54/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 9.0928 - val_loss: 16.0365\n",
      "Epoch 55/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 8.9722 - val_loss: 16.9874\n",
      "Epoch 56/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 9.1340 - val_loss: 18.3331\n",
      "Epoch 57/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 8.8530 - val_loss: 15.9403\n",
      "Epoch 58/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 8.8181 - val_loss: 16.0515\n",
      "Epoch 59/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 8.3714 - val_loss: 15.8030\n",
      "Epoch 60/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 8.3600 - val_loss: 15.7358\n",
      "Epoch 61/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 8.2528 - val_loss: 15.7273\n",
      "Epoch 62/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 8.3100 - val_loss: 16.4183\n",
      "Epoch 63/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 8.1186 - val_loss: 16.1639\n",
      "Epoch 64/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 8.0545 - val_loss: 15.3592\n",
      "Epoch 65/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 7.8529 - val_loss: 17.4660\n",
      "Epoch 66/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 7.8568 - val_loss: 15.7169\n",
      "Epoch 67/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 7.6739 - val_loss: 15.2753\n",
      "Epoch 68/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 7.9595 - val_loss: 15.8971\n",
      "Epoch 69/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 7.4814 - val_loss: 16.2782\n",
      "Epoch 70/100\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 7.6833 - val_loss: 15.8602\n",
      "Epoch 71/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 7.8383 - val_loss: 14.6866\n",
      "Epoch 72/100\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 7.5673 - val_loss: 15.3315\n",
      "Epoch 73/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 7.2833 - val_loss: 17.1623\n",
      "Epoch 74/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 7.4078 - val_loss: 15.0398\n",
      "Epoch 75/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 7.0486 - val_loss: 16.0461\n",
      "Epoch 76/100\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 7.0698 - val_loss: 14.5972\n",
      "Epoch 77/100\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 7.2006 - val_loss: 16.2513\n",
      "Epoch 78/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 7.2585 - val_loss: 16.7857\n",
      "Epoch 79/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 6.7030 - val_loss: 15.4102\n",
      "Epoch 80/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 7.1481 - val_loss: 14.4052\n",
      "Epoch 81/100\n",
      "252/252 [==============================] - 3s 11ms/step - loss: 6.7226 - val_loss: 14.0571\n",
      "Epoch 82/100\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 6.3907 - val_loss: 14.6913\n",
      "Epoch 83/100\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 7.2312 - val_loss: 14.8022\n",
      "Epoch 84/100\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 6.4493 - val_loss: 14.4404\n",
      "Epoch 85/100\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 6.3769 - val_loss: 14.5962\n",
      "Epoch 86/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 6.2223 - val_loss: 14.1974\n",
      "Epoch 87/100\n",
      "252/252 [==============================] - 3s 11ms/step - loss: 6.6001 - val_loss: 14.1519\n",
      "Epoch 88/100\n",
      "252/252 [==============================] - 3s 11ms/step - loss: 6.2905 - val_loss: 14.4298\n",
      "Epoch 89/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 6.3235 - val_loss: 14.5550\n",
      "Epoch 90/100\n",
      "252/252 [==============================] - 3s 11ms/step - loss: 6.7752 - val_loss: 13.7853\n",
      "Epoch 91/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 6.3155 - val_loss: 14.1521\n",
      "Epoch 92/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 6.2222 - val_loss: 13.8080\n",
      "Epoch 93/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 5.8437 - val_loss: 14.0482\n",
      "Epoch 94/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 5.8367 - val_loss: 13.1852\n",
      "Epoch 95/100\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 6.1448 - val_loss: 14.6807\n",
      "Epoch 96/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 6.3537 - val_loss: 14.0037\n",
      "Epoch 97/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 6.3958 - val_loss: 14.5625\n",
      "Epoch 98/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 5.8705 - val_loss: 13.9527\n",
      "Epoch 99/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 5.4259 - val_loss: 14.4134\n",
      "Epoch 100/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 5.8199 - val_loss: 14.9795\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 11.1679\n",
      "Test Loss: 11.167887687683105\n",
      "79/79 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_dim = 30  \n",
    "num_heads = 2   \n",
    "ff_dim = 64   \n",
    "\n",
    "model = Sequential([\n",
    "    TransformerBlock(embed_dim, num_heads, ff_dim),\n",
    "    Dense(1)  \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 11.167887762631565\n",
      "Test MAE: 2.1457099391729515\n",
      "R-squared (R2): 0.854511921153014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f'Test MSE: {mse}')\n",
    "print(f'Test MAE: {mae}')\n",
    "print(f\"R-squared (R2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   los_icu  Predicted LOS_ICU\n",
      "0     4.94           6.716133\n",
      "1     1.01           0.238064\n",
      "2     2.70           4.192300\n",
      "3     3.18           3.707989\n",
      "4     8.96           7.711873\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Predicted LOS_ICU'])\n",
    "y_test_df = pd.DataFrame(y_test, columns=['los_icu'])\n",
    "\n",
    "\n",
    "predictions_df.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "comparison_df = pd.concat([y_test_df, predictions_df], axis=1)\n",
    "\n",
    "print(comparison_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aniongap                                                          0.059016\n",
      "bicarbonate                                                       0.070384\n",
      "bun                                                               0.034100\n",
      "calcium                                                           0.038278\n",
      "chloride                                                          0.014794\n",
      "                                                                    ...   \n",
      "first_careunit_Neuro Intermediate                                 0.004587\n",
      "first_careunit_Neuro Stepdown                                     0.009522\n",
      "first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)    0.030888\n",
      "first_careunit_Surgical Intensive Care Unit (SICU)                0.047393\n",
      "first_careunit_Trauma SICU (TSICU)                                0.037423\n",
      "Name: los_icu, Length: 97, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "survived_df.drop('id', axis=1, inplace=True)\n",
    "correlation_matrix = survived_df.corr()\n",
    "abs_target_correlation = correlation_matrix['los_icu'].abs()\n",
    "\n",
    "print(abs_target_correlation.drop('los_icu', axis=0))\n",
    "N = 30  \n",
    "top_features = abs_target_correlation.drop('los_icu', axis=0).nlargest(N).index.tolist()\n",
    "\n",
    "X = survived_df[top_features]\n",
    "y=survived_df['los_icu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "252/252 [==============================] - 7s 8ms/step - loss: 5.6854 - val_loss: 14.0614\n",
      "Epoch 2/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 5.7592 - val_loss: 14.5209\n",
      "Epoch 3/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 6.2338 - val_loss: 15.0658\n",
      "Epoch 4/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 5.5718 - val_loss: 13.9980\n",
      "Epoch 5/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 5.5738 - val_loss: 14.3581\n",
      "Epoch 6/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 5.5554 - val_loss: 13.5704\n",
      "Epoch 7/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 5.5461 - val_loss: 13.6227\n",
      "Epoch 8/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 5.3637 - val_loss: 14.0638\n",
      "Epoch 9/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 5.5752 - val_loss: 14.3466\n",
      "Epoch 10/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 5.1796 - val_loss: 13.2630\n",
      "Epoch 11/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 5.1614 - val_loss: 15.0444\n",
      "Epoch 12/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 5.2542 - val_loss: 14.0568\n",
      "Epoch 13/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 5.8277 - val_loss: 15.5173\n",
      "Epoch 14/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 5.4679 - val_loss: 14.3282\n",
      "Epoch 15/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 5.4268 - val_loss: 13.2689\n",
      "Epoch 16/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 5.1416 - val_loss: 13.6816\n",
      "Epoch 17/100\n",
      "252/252 [==============================] - 3s 11ms/step - loss: 5.0200 - val_loss: 14.6087\n",
      "Epoch 18/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 5.0726 - val_loss: 12.9187\n",
      "Epoch 19/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 5.1858 - val_loss: 13.6168\n",
      "Epoch 20/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.9843 - val_loss: 14.4633\n",
      "Epoch 21/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 4.8941 - val_loss: 13.7003\n",
      "Epoch 22/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 4.8968 - val_loss: 13.0976\n",
      "Epoch 23/100\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 4.9197 - val_loss: 13.4580\n",
      "Epoch 24/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 4.9329 - val_loss: 13.3053\n",
      "Epoch 25/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 4.7352 - val_loss: 14.0130\n",
      "Epoch 26/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.9753 - val_loss: 12.9999\n",
      "Epoch 27/100\n",
      "252/252 [==============================] - 3s 11ms/step - loss: 4.8395 - val_loss: 13.1125\n",
      "Epoch 28/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 5.0527 - val_loss: 12.8203\n",
      "Epoch 29/100\n",
      "252/252 [==============================] - 3s 11ms/step - loss: 4.8416 - val_loss: 14.8758\n",
      "Epoch 30/100\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 4.9178 - val_loss: 12.9353\n",
      "Epoch 31/100\n",
      "252/252 [==============================] - 3s 11ms/step - loss: 4.5478 - val_loss: 13.3267\n",
      "Epoch 32/100\n",
      "252/252 [==============================] - 3s 11ms/step - loss: 4.6146 - val_loss: 12.7380\n",
      "Epoch 33/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.6195 - val_loss: 13.5448\n",
      "Epoch 34/100\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 4.5862 - val_loss: 14.2980\n",
      "Epoch 35/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 4.5580 - val_loss: 12.8076\n",
      "Epoch 36/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 4.5485 - val_loss: 13.0194\n",
      "Epoch 37/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 4.6992 - val_loss: 12.8838\n",
      "Epoch 38/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 4.8992 - val_loss: 14.2343\n",
      "Epoch 39/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 4.6392 - val_loss: 12.7765\n",
      "Epoch 40/100\n",
      "252/252 [==============================] - 2s 9ms/step - loss: 4.3626 - val_loss: 12.6603\n",
      "Epoch 41/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 4.4313 - val_loss: 12.8674\n",
      "Epoch 42/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 4.4917 - val_loss: 13.2704\n",
      "Epoch 43/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.5574 - val_loss: 12.7963\n",
      "Epoch 44/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.2902 - val_loss: 12.7077\n",
      "Epoch 45/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.1538 - val_loss: 12.4433\n",
      "Epoch 46/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 4.4039 - val_loss: 12.9907\n",
      "Epoch 47/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.4157 - val_loss: 12.9487\n",
      "Epoch 48/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.1989 - val_loss: 13.5244\n",
      "Epoch 49/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.5451 - val_loss: 15.2499\n",
      "Epoch 50/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.6655 - val_loss: 14.3000\n",
      "Epoch 51/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 4.1295 - val_loss: 12.6040\n",
      "Epoch 52/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 4.1304 - val_loss: 12.4184\n",
      "Epoch 53/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 3.9873 - val_loss: 12.2963\n",
      "Epoch 54/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.4829 - val_loss: 12.7428\n",
      "Epoch 55/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 4.4507 - val_loss: 12.5485\n",
      "Epoch 56/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.1388 - val_loss: 12.5606\n",
      "Epoch 57/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.1960 - val_loss: 12.5142\n",
      "Epoch 58/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 4.0567 - val_loss: 12.1000\n",
      "Epoch 59/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 4.0306 - val_loss: 12.0249\n",
      "Epoch 60/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 4.0736 - val_loss: 13.4646\n",
      "Epoch 61/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 4.2485 - val_loss: 12.4133\n",
      "Epoch 62/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 3.9697 - val_loss: 12.3767\n",
      "Epoch 63/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 4.0552 - val_loss: 11.6034\n",
      "Epoch 64/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 4.0902 - val_loss: 12.7038\n",
      "Epoch 65/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 4.2582 - val_loss: 12.1970\n",
      "Epoch 66/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 4.0760 - val_loss: 12.2420\n",
      "Epoch 67/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 3.8998 - val_loss: 12.2645\n",
      "Epoch 68/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 4.1154 - val_loss: 13.1777\n",
      "Epoch 69/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 3.8812 - val_loss: 12.3041\n",
      "Epoch 70/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 3.9148 - val_loss: 12.1036\n",
      "Epoch 71/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 3.9912 - val_loss: 13.3588\n",
      "Epoch 72/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 4.3076 - val_loss: 12.8748\n",
      "Epoch 73/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 3.9452 - val_loss: 13.0122\n",
      "Epoch 74/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 3.8532 - val_loss: 13.6460\n",
      "Epoch 75/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 3.9881 - val_loss: 12.0105\n",
      "Epoch 76/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 3.6338 - val_loss: 11.8516\n",
      "Epoch 77/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 3.6599 - val_loss: 11.9254\n",
      "Epoch 78/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 3.6224 - val_loss: 11.6443\n",
      "Epoch 79/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 3.7227 - val_loss: 12.1385\n",
      "Epoch 80/100\n",
      "252/252 [==============================] - 2s 10ms/step - loss: 4.0754 - val_loss: 13.1307\n",
      "Epoch 81/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 3.9350 - val_loss: 11.9042\n",
      "Epoch 82/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 3.9265 - val_loss: 12.8095\n",
      "Epoch 83/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 3.9563 - val_loss: 12.3215\n",
      "Epoch 84/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 3.6611 - val_loss: 12.1889\n",
      "Epoch 85/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 3.5619 - val_loss: 13.7760\n",
      "Epoch 86/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 3.7493 - val_loss: 11.7376\n",
      "Epoch 87/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 3.7120 - val_loss: 11.3738\n",
      "Epoch 88/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 3.5544 - val_loss: 12.9382\n",
      "Epoch 89/100\n",
      "252/252 [==============================] - 2s 8ms/step - loss: 4.7766 - val_loss: 12.7585\n",
      "Epoch 90/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 3.7613 - val_loss: 11.8128\n",
      "Epoch 91/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 3.4541 - val_loss: 12.0968\n",
      "Epoch 92/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 3.5742 - val_loss: 11.9236\n",
      "Epoch 93/100\n",
      "252/252 [==============================] - 2s 6ms/step - loss: 3.5002 - val_loss: 12.5241\n",
      "Epoch 94/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 3.5285 - val_loss: 13.1460\n",
      "Epoch 95/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 3.6623 - val_loss: 12.0730\n",
      "Epoch 96/100\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 3.7784 - val_loss: 11.4256\n",
      "Epoch 97/100\n",
      "252/252 [==============================] - 1s 5ms/step - loss: 3.4744 - val_loss: 11.7067\n",
      "Epoch 98/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 3.5199 - val_loss: 11.9071\n",
      "Epoch 99/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 3.4540 - val_loss: 12.3375\n",
      "Epoch 100/100\n",
      "252/252 [==============================] - 2s 7ms/step - loss: 3.6029 - val_loss: 11.6042\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8.7571\n",
      "Test Loss: 8.757076263427734\n",
      "79/79 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "\n",
    "\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 8.757076177429752\n",
      "Test MAE: 1.8287517482141735\n",
      "R-squared (R2): 0.8859184282247166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f'Test MSE: {mse}')\n",
    "print(f'Test MAE: {mae}')\n",
    "print(f\"R-squared (R2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
